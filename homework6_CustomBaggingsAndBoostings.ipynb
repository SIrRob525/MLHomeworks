{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Домашняя работа 6. Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная оценка 10 баллов\n",
    "\n",
    "Ответы на вопросы пишите в комментариях или в markdown ячейках. Таким же образом обозначайте блоки кода для лучшей читаемости (например, \"Обучим бэггинг на логистических регрессиях : ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\").\n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "**Оценка: 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GOqjUI6igeLc"
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tKaz0okgeLh"
   },
   "source": [
    "### Задание 1. Градиентный бустинг своими руками  (4 балла)\n",
    "\n",
    "Вам нужно реализовать упрощенный вариант градиентного бутсинга для задачи регресси. \n",
    "\n",
    "\n",
    "**Напоминание, как это работает:**\n",
    "\n",
    "Обозначим текущую композицию на $N-1$ шаге за $a_{N - 1}(x_i)$. Базовый алгоритм $b_N(x_i)$ обучается на ответах $-\\frac{\\partial L(y_i, z)}{\\partial z}\\Bigl|_{z = a_{N - 1}(x_i)}$, где $L(y_i, z)$ — значение функции потерь на объекте при правильном ответе $y_i$ и предсказании $z$. Композиция на следующем шаге получается так:\n",
    "\n",
    "$$\n",
    "a_N(x_i) = a_{N-1}(x_i) + \\nu\\gamma_Nb_N(x_i)\n",
    "$$\n",
    "\n",
    "Здесь $\\nu \\in [0, 1]$ — темп обучения (гиперпараметр), $\\gamma_N$ — оптимальный вес, настраиваемый на каждом шаге алгоритма в ходе решения оптимизационной задачи:\n",
    "\n",
    "$$\n",
    "\\gamma_N = \\mathrm{arg}\\min_\\gamma \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}L\\left(y_i, a_{N - 1}(x_i) + \\gamma b_N(x_i)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Заметьте, что в формуле выше нет $\\nu$. Этот гиперпараметр используется для сокращения длины шага, оптимального при составлении композиции $a_N$. Идея отклонения от оптимума должна быть вам уже знакома как способ борьбы с переобучением, когда мы специально форсим модель работать чуть хуже, чем могла бы, на текущем шаге, чтобы сохранить обобщающую способность и не подогнаться под тренировочную выборку (или под шум).\n",
    "\n",
    "С потерей в 0.5 балла можете принять $\\gamma_N = 1$ для каждого $N$. На полный балл необходимо реализовать нахождение оптимального $\\gamma_N$ на каждом шаге.\n",
    "\n",
    "В качестве функции потерь $L$ возьмите MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базовой модели можете использовать `DecisionTreeRegressor` из `sklearn`.\n",
    "Для решения оптимизационной задачки можно воспользоваться алгоритмами из любых библиотек, например, `scipy.optimize`, или найти оптимум перебором по сетке из некоторого разумного диапазона.\n",
    "\n",
    "Можно дописывать свои функции, если необходимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZB5Yt-LKgeLi"
   },
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(\n",
    "        self, \n",
    "        base_model_class: object = DecisionTreeRegressor,\n",
    "        base_model_params: dict = {'max_depth': None}, \n",
    "        n_estimators: int = 10,\n",
    "        learning_rate: float = 0.1,\n",
    "        random_state: int = 0,\n",
    "        show_progress: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "          base_model_class: Class of the base learner.\n",
    "\n",
    "          base_model_params: Hyperparameters of the base learner.\n",
    "          \n",
    "          n_estimators: Number of boosting stages.\n",
    "          \n",
    "          learning_rate: Value used to shrink contribution of each base learner to the model. \n",
    "          \n",
    "        \"\"\"\n",
    "        \n",
    "        self.base_model_class = base_model_class\n",
    "        self.base_model_params = base_model_params\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.show_progress = show_progress\n",
    "        \n",
    "        # list for optimal gammas at each iteration\n",
    "        self.gammas = []\n",
    "        \n",
    "        # list for base models\n",
    "        self.models = []\n",
    "\n",
    "        #last prediction for every object\n",
    "        self._last_pred = None\n",
    "        \n",
    "        \n",
    "    def find_optimal_gamma(self, \n",
    "                           y: np.array, \n",
    "                           old_predictions: np.array,\n",
    "                           new_predictions: np.array) -> float:\n",
    "        \"\"\"You may add arguments if it's necessary for your optimization algorithm.\n",
    "        \n",
    "        Args:\n",
    "          y: Target variable.\n",
    "\n",
    "          old_predictions: Prediction of the additive model at the previous stage.\n",
    "          \n",
    "          new_predictions: Prediction of the base learner at the current stage. \n",
    "          \n",
    "        Returns:\n",
    "          Optimal value for gamma.\n",
    "          \n",
    "        \"\"\"\n",
    "        return np.dot(y - old_predictions, new_predictions) / np.dot(new_predictions, new_predictions) #vertex of the parabola\n",
    "    \n",
    "    \n",
    "    def _fit_base_model(self, X: np.ndarray, y: np.array):\n",
    "        \"\"\"Train one base learner. \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "          \n",
    "          y: Target variable.\n",
    "          \n",
    "          \n",
    "        Returns:\n",
    "          Fitted base learner.\n",
    "          \n",
    "        \"\"\"\n",
    "        new_model = DecisionTreeRegressor(**self.base_model_params)\n",
    "        new_model.fit(X, y)\n",
    "        return new_model\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.array):\n",
    "        \"\"\"Train boosting (\"sum\" of base learners). \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "          \n",
    "          y: Target variable.\n",
    "          \n",
    "          \n",
    "        Returns:\n",
    "          Fitted boosting.\n",
    "          \n",
    "        \"\"\"\n",
    "        for _ in tqdm(range(self.n_estimators), disable=(not self.show_progress)):\n",
    "            \n",
    "            np.random.seed(seed=self.random_state)\n",
    "            \n",
    "            if self._last_pred is None: self._last_pred = np.zeros(y.shape[0])    #setting initial prediction as constant 0\n",
    "\n",
    "            composition_pred = self._last_pred                  \n",
    "            residuals = 2 * (composition_pred - y)                                #calculating prediction of the current composition, and the residuals\n",
    "\n",
    "            model = self._fit_base_model(X, residuals)                            #training base model on residuals\n",
    "            self.models.append(model)\n",
    "\n",
    "            base_model_pred = model.predict(X)\n",
    "            gamma = self.find_optimal_gamma(y, self._last_pred, base_model_pred)  #finding optimal gamma\n",
    "            self.gammas.append(gamma)\n",
    "            self._last_pred += self.learning_rate * gamma * base_model_pred       #updating predictions\n",
    "            \n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"Make prediction of fitted boosting. \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "\n",
    "\n",
    "        Returns:\n",
    "          Prediction of fitted boosting.\n",
    "          \n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i in range(self.n_estimators):\n",
    "            y_pred += self.learning_rate * self.gammas[i] * self.models[i].predict(X)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Комментарии:*\n",
    "1. Добавил поле `_last_pred`, в котором записаны последние предсказания модели по всей выборке\n",
    "2. Обучаю базовые модели и считаю гамму на bootstrap-подвыборках\n",
    "3. Добавил параметр random_state в инициализаторе\n",
    "4. Добавил параметр show_progress, отвечающий за отображение шкалы прогресса в методе `fit`\n",
    "\n",
    "В остальном все стандартно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте вашу реализацию на бостонском датасете. Подберите оптимальные гиперпараметры, чтобы победить RandomForestRegressor (не меняйте параметры сида)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X = housing.data[:5000]\n",
    "y = housing.target[:5000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02283901441436567\n",
      "0.1673784076585523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(max_features=4, n_estimators=640, random_state=19052019)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_error = mean_squared_error(y_train, rf.predict(X_train))\n",
    "rf_test_error = mean_squared_error(y_test, rf.predict(X_test))\n",
    "print(rf_train_error, rf_test_error, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в данном случае переобучена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncareful! runs for around 8 minutes!\\n\\nfor n_estimators in tqdm(range(5, 51, 5)):\\n    for max_depth in tqdm(range(1, 7)):\\n        for lr in range(1, 21):\\n            gb = GradientBoosting(n_estimators=n_estimators, base_model_params={'max_depth' : max_depth}, learning_rate=lr/100, random_state=19052019, show_progress=False)\\n            gb.fit(X_train, y_train)\\n\\n            err = mean_squared_error(y_test, gb.predict(X_test))\\n            if err < rf_error:\\n                print(f'error: {err}\\n n: {n_estimators}\\n max_depth: {max_depth}\\n learning_rate: {lr / 100}')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "careful! runs for around 8 minutes!\n",
    "\n",
    "for n_estimators in tqdm(range(5, 51, 5)):\n",
    "    for max_depth in tqdm(range(1, 7)):\n",
    "        for lr in range(1, 21):\n",
    "            gb = GradientBoosting(n_estimators=n_estimators, base_model_params={'max_depth' : max_depth}, learning_rate=lr/100, random_state=19052019, show_progress=False)\n",
    "            gb.fit(X_train, y_train)\n",
    "\n",
    "            err = mean_squared_error(y_test, gb.predict(X_test))\n",
    "            if err < rf_error:\n",
    "                print(f'error: {err}\\n n: {n_estimators}\\n max_depth: {max_depth}\\n learning_rate: {lr / 100}')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначально вручную удалось засечь, что начиная примерно с `max_depth = 5` и `learning_rate = 5 / n` модель начинает переобучаться, при этом изменения `n` особо не влияют (приходится понижать `learning rate` и получается то же самое, что логично). С помощью перебора выше удалось найти два набора параметров, при которых мы побеждаем случайный лес. При этом видно, что модель сильно переобучается. Мне кажется, что нам просто повезло, шум обучающей и тестовой выборки совпал и получилась относительно низкая ошибка. В реальности логично выбирать другие параметры, при которых на обучающей и тестовой выборке ошибка близка, но все равно какой-то степени переобучения избежать не удастся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 39.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049874058311388914\n",
      "0.16659537024916787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoosting(n_estimators=40, base_model_params={'max_depth' : 6}, learning_rate=0.17, random_state=19052019, show_progress=True)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "print(mean_squared_error(y_train, gb.predict(X_train)),\n",
    "      mean_squared_error(y_test, gb.predict(X_test)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Сравнение подходов (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте данные о выдаче кредитов. Это данные с kaggle, целевая переменная `y` показывает, вернуло ли кредит физическое лицо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>38</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>33</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.291</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.967</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>61</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.406</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>37</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          job   marital          education  default housing loan  \\\n",
       "7103   38       admin.  divorced  university.degree       no     yes   no   \n",
       "2987   33  blue-collar    single           basic.6y       no     yes   no   \n",
       "6480   57  blue-collar   married            unknown  unknown     yes   no   \n",
       "186    61       admin.   married  university.degree       no     yes  yes   \n",
       "3299   37    housemaid   married        high.school       no     yes  yes   \n",
       "\n",
       "        contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "7103   cellular   aug         fri  ...         4    999         0   \n",
       "2987   cellular   may         tue  ...         3    999         1   \n",
       "6480   cellular   aug         wed  ...         2    999         0   \n",
       "186    cellular   apr         thu  ...         5    999         0   \n",
       "3299  telephone   may         fri  ...         6    999         0   \n",
       "\n",
       "         poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "7103  nonexistent          1.4          93.444          -36.1      4.964   \n",
       "2987      failure         -1.8          92.893          -46.2      1.291   \n",
       "6480  nonexistent          1.4          93.444          -36.1      4.967   \n",
       "186   nonexistent         -1.8          93.075          -47.1      1.406   \n",
       "3299  nonexistent          1.1          93.994          -36.4      4.864   \n",
       "\n",
       "      nr.employed  y  \n",
       "7103       5228.1 -1  \n",
       "2987       5099.1  1  \n",
       "6480       5228.1 -1  \n",
       "186        5099.1  1  \n",
       "3299       5191.0 -1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://www.dropbox.com/s/uy27mctxo0gbuof/bank_data.csv?dl=1')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решите задачу предсказания возвращения кредита методами, перечисленными ниже:\n",
    "\n",
    "- Случайный лес\n",
    "- Бэггинг на деревьях (поставьте для базовых деревьев min_samples_leaf=1)\n",
    "- Бэггинг, у которого базовой моделью является бустинг с большим числом деревьев (> 100)\n",
    "- Бэггинг на логистических регрессиях\n",
    "\n",
    "Используйте логистическую регрессию, случайный лес, `GradientBoostingClassifier` и `BaggingClassifier` из `sklearn`.\n",
    "\n",
    "1) Какая из моделей имеет лучшее качество? С чем это связано?\n",
    "\n",
    "2) Какая из моделей сильнее всего переобучается?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала выделим категориальные признаки и применим one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.968</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.838</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0   39        67         3    999         0           1.4          93.918   \n",
       "1   31       522         1    999         0           1.4          93.918   \n",
       "2   34        84         1    999         0          -1.8          92.893   \n",
       "3   23       332         2    999         0           1.4          93.918   \n",
       "4   63       479         1    999         0          -2.9          92.201   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  ...  month_oct  month_sep  \\\n",
       "0          -42.7      4.968       5228.1  ...          0          0   \n",
       "1          -42.7      4.960       5228.1  ...          0          0   \n",
       "2          -46.2      1.250       5099.1  ...          0          0   \n",
       "3          -42.7      4.963       5228.1  ...          0          0   \n",
       "4          -31.4      0.838       5076.2  ...          0          0   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                0                0                1                0   \n",
       "1                0                1                0                0   \n",
       "2                1                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \n",
       "0                0                 0                     1                 0  \n",
       "1                0                 0                     1                 0  \n",
       "2                0                 0                     1                 0  \n",
       "3                1                 0                     1                 0  \n",
       "4                0                 0                     1                 0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'y']\n",
    "y = df.loc[:, \"y\"]\n",
    "numeric = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "for column in X.columns[~X.columns.isin(numeric)]:\n",
    "    one_hot = pd.get_dummies(X[column], prefix=column, dtype=int)\n",
    "    #print(one_hot)\n",
    "    X = X.drop(column, axis = 1)\n",
    "    X = X.join(one_hot)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained\n",
      "Bagging on Desicion Trees trained\n",
      "Bagging on Gradient Boostings trained\n",
      "Bagging on Logistic Regressions trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train error</th>\n",
       "      <th>test error</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615517</td>\n",
       "      <td>0.846121</td>\n",
       "      <td>0.859634</td>\n",
       "      <td>0.834179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging on Desicion Trees</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674138</td>\n",
       "      <td>0.831466</td>\n",
       "      <td>0.841832</td>\n",
       "      <td>0.824027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging on Gradient Boostings</td>\n",
       "      <td>0.350575</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>0.888793</td>\n",
       "      <td>0.870192</td>\n",
       "      <td>0.918782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging on Logistic Regressions</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.563793</td>\n",
       "      <td>0.888793</td>\n",
       "      <td>0.870192</td>\n",
       "      <td>0.918782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  train error  test error  accuracy  \\\n",
       "0                    Random Forest     0.000000    0.615517  0.846121   \n",
       "1        Bagging on Desicion Trees     0.000000    0.674138  0.831466   \n",
       "2    Bagging on Gradient Boostings     0.350575    0.444828  0.888793   \n",
       "3  Bagging on Logistic Regressions     0.505747    0.563793  0.888793   \n",
       "\n",
       "   precision    recall  \n",
       "0   0.859634  0.834179  \n",
       "1   0.841832  0.824027  \n",
       "2   0.870192  0.918782  \n",
       "3   0.870192  0.918782  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=10, bootstrap=False)\n",
    "dt = BaggingClassifier(estimator=DecisionTreeClassifier(min_samples_leaf=1), n_estimators=10, bootstrap=False)\n",
    "gb = BaggingClassifier(estimator=GradientBoostingClassifier(n_estimators=200), n_estimators=10, bootstrap=False)\n",
    "lr = BaggingClassifier(estimator=LogisticRegression(max_iter=5000), n_estimators=10, bootstrap=False)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print('Random Forest trained')\n",
    "dt.fit(X_train, y_train)\n",
    "print('Bagging on Desicion Trees trained')\n",
    "gb.fit(X_train, y_train)\n",
    "print('Bagging on Gradient Boostings trained')\n",
    "lr.fit(X_train, y_train)\n",
    "print('Bagging on Logistic Regressions trained')\n",
    "\n",
    "rf_train_pred = rf.predict(X_train)\n",
    "dt_train_pred = dt.predict(X_train)\n",
    "gb_train_pred = gb.predict(X_train)\n",
    "lr_train_pred = lr.predict(X_train)\n",
    "\n",
    "rf_test_pred = rf.predict(X_test)\n",
    "dt_test_pred = dt.predict(X_test)\n",
    "gb_test_pred = gb.predict(X_test)\n",
    "lr_test_pred = lr.predict(X_test)\n",
    "\n",
    "data = [['Random Forest', \n",
    "            mean_squared_error(y_train, rf_train_pred), \n",
    "            mean_squared_error(y_test, rf_test_pred), \n",
    "            accuracy_score(y_test, rf_test_pred), \n",
    "            precision_score(y_test, rf_test_pred), \n",
    "            recall_score(y_test, rf_test_pred)],\n",
    "        ['Bagging on Desicion Trees', \n",
    "            mean_squared_error(y_train, dt_train_pred), \n",
    "            mean_squared_error(y_test, dt_test_pred), \n",
    "            accuracy_score(y_test, dt_test_pred), \n",
    "            precision_score(y_test, dt_test_pred), \n",
    "            recall_score(y_test, dt_test_pred)],\n",
    "        ['Bagging on Gradient Boostings', \n",
    "            mean_squared_error(y_train, gb_train_pred), \n",
    "            mean_squared_error(y_test, gb_test_pred), \n",
    "            accuracy_score(y_test, gb_test_pred), \n",
    "            precision_score(y_test, gb_test_pred), \n",
    "            recall_score(y_test, gb_test_pred)],\n",
    "        ['Bagging on Logistic Regressions', \n",
    "            mean_squared_error(y_train, lr_train_pred), \n",
    "            mean_squared_error(y_test, lr_test_pred), \n",
    "            accuracy_score(y_test, gb_test_pred), \n",
    "            precision_score(y_test, gb_test_pred), \n",
    "            recall_score(y_test, gb_test_pred)]]\n",
    "\n",
    "res = pd.DataFrame(data, columns=['model', 'train error', 'test error', 'accuracy', 'precision', 'recall'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Современные бустинги (3 балла)\n",
    "\n",
    "Сравните на этих данных любую из трёх популярных имплементаций градиентного бустинга (xgboost, lightgbm, catboost). Подберите основные гиперпараметры (число деревьев, длина шага, глубина дерева/число листьев). Получилось ли круче, чем с моделями выше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ibori\\Desktop\\ДЗ Совбак\\3 семестр\\Машинное обучение\\homework_6.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/%D0%94%D0%97%20%D0%A1%D0%BE%D0%B2%D0%B1%D0%B0%D0%BA/3%20%D1%81%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5/homework_6.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcatboost\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw8-boosting-clustering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
