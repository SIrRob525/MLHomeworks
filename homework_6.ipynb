{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Домашняя работа 6. Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная оценка 10 баллов\n",
    "\n",
    "Ответы на вопросы пишите в комментариях или в markdown ячейках. Таким же образом обозначайте блоки кода для лучшей читаемости (например, \"Обучим бэггинг на логистических регрессиях : ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\").\n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "**Оценка: 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOqjUI6igeLc"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\ibori\\Desktop\\Homeworks\\sem3\\ML_1\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\ibori\\Desktop\\Homeworks\\sem3\\ML_1 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# !pip install numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tKaz0okgeLh"
   },
   "source": [
    "### Задание 1. Градиентный бустинг своими руками  (4 балла)\n",
    "\n",
    "Вам нужно реализовать упрощенный вариант градиентного бутсинга для задачи регресси. \n",
    "\n",
    "\n",
    "**Напоминание, как это работает:**\n",
    "\n",
    "Обозначим текущую композицию на $N-1$ шаге за $a_{N - 1}(x_i)$. Базовый алгоритм $b_N(x_i)$ обучается на ответах $-\\frac{\\partial L(y_i, z)}{\\partial z}\\Bigl|_{z = a_{N - 1}(x_i)}$, где $L(y_i, z)$ — значение функции потерь на объекте при правильном ответе $y_i$ и предсказании $z$. Композиция на следующем шаге получается так:\n",
    "\n",
    "$$\n",
    "a_N(x_i) = a_{N-1}(x_i) + \\nu\\gamma_Nb_N(x_i)\n",
    "$$\n",
    "\n",
    "Здесь $\\nu \\in [0, 1]$ — темп обучения (гиперпараметр), $\\gamma_N$ — оптимальный вес, настраиваемый на каждом шаге алгоритма в ходе решения оптимизационной задачи:\n",
    "\n",
    "$$\n",
    "\\gamma_N = \\mathrm{arg}\\min_\\gamma \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}L\\left(y_i, a_{N - 1}(x_i) + \\gamma b_N(x_i)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Заметьте, что в формуле выше нет $\\nu$. Этот гиперпараметр используется для сокращения длины шага, оптимального при составлении композиции $a_N$. Идея отклонения от оптимума должна быть вам уже знакома как способ борьбы с переобучением, когда мы специально форсим модель работать чуть хуже, чем могла бы, на текущем шаге, чтобы сохранить обобщающую способность и не подогнаться под тренировочную выборку (или под шум).\n",
    "\n",
    "С потерей в 0.5 балла можете принять $\\gamma_N = 1$ для каждого $N$. На полный балл необходимо реализовать нахождение оптимального $\\gamma_N$ на каждом шаге.\n",
    "\n",
    "В качестве функции потерь $L$ возьмите MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базовой модели можете использовать `DecisionTreeRegressor` из `sklearn`.\n",
    "Для решения оптимизационной задачки можно воспользоваться алгоритмами из любых библиотек, например, `scipy.optimize`, или найти оптимум перебором по сетке из некоторого разумного диапазона.\n",
    "\n",
    "Можно дописывать свои функции, если необходимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZB5Yt-LKgeLi"
   },
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(\n",
    "        self, \n",
    "        base_model_class: object = DecisionTreeRegressor,\n",
    "        base_model_params: dict = {'max_depth': None}, \n",
    "        n_estimators: int = 10,\n",
    "        learning_rate: float = 0.1,\n",
    "        random_state: int = 0,\n",
    "        show_progress: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "          base_model_class: Class of the base learner.\n",
    "\n",
    "          base_model_params: Hyperparameters of the base learner.\n",
    "          \n",
    "          n_estimators: Number of boosting stages.\n",
    "          \n",
    "          learning_rate: Value used to shrink contribution of each base learner to the model. \n",
    "          \n",
    "        \"\"\"\n",
    "        \n",
    "        self.base_model_class = base_model_class\n",
    "        self.base_model_params = base_model_params\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.show_progress = show_progress\n",
    "        \n",
    "        # list for optimal gammas at each iteration\n",
    "        self.gammas = []\n",
    "        \n",
    "        # list for base models\n",
    "        self.models = []\n",
    "\n",
    "        #last prediction for every object\n",
    "        self._last_pred = None\n",
    "        \n",
    "        \n",
    "    def find_optimal_gamma(self, \n",
    "                           y: np.array, \n",
    "                           old_predictions: np.array,\n",
    "                           new_predictions: np.array) -> float:\n",
    "        \"\"\"You may add arguments if it's necessary for your optimization algorithm.\n",
    "        \n",
    "        Args:\n",
    "          y: Target variable.\n",
    "\n",
    "          old_predictions: Prediction of the additive model at the previous stage.\n",
    "          \n",
    "          new_predictions: Prediction of the base learner at the current stage. \n",
    "          \n",
    "        Returns:\n",
    "          Optimal value for gamma.\n",
    "          \n",
    "        \"\"\"\n",
    "        return np.dot(y - old_predictions, new_predictions) / np.dot(new_predictions, new_predictions) #vertex of the parabola\n",
    "    \n",
    "    \n",
    "    def _fit_base_model(self, X: np.ndarray, y: np.array):\n",
    "        \"\"\"Train one base learner. \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "          \n",
    "          y: Target variable.\n",
    "          \n",
    "          \n",
    "        Returns:\n",
    "          Fitted base learner.\n",
    "          \n",
    "        \"\"\"\n",
    "        new_model = DecisionTreeRegressor(**self.base_model_params)\n",
    "        new_model.fit(X, y)\n",
    "        return new_model\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.array):\n",
    "        \"\"\"Train boosting (\"sum\" of base learners). \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "          \n",
    "          y: Target variable.\n",
    "          \n",
    "          \n",
    "        Returns:\n",
    "          Fitted boosting.\n",
    "          \n",
    "        \"\"\"\n",
    "        for _ in tqdm(range(self.n_estimators), disable=(not self.show_progress)):\n",
    "            \n",
    "            np.random.seed(seed=self.random_state)\n",
    "            \n",
    "            if self._last_pred is None: self._last_pred = np.zeros(y.shape[0])    #setting initial prediction as constant 0\n",
    "\n",
    "            composition_pred = self._last_pred                  \n",
    "            residuals = 2 * (composition_pred - y)                                #calculating prediction of the current composition, and the residuals\n",
    "\n",
    "            model = self._fit_base_model(X, residuals)                            #training base model on residuals\n",
    "            self.models.append(model)\n",
    "\n",
    "            base_model_pred = model.predict(X)\n",
    "            gamma = self.find_optimal_gamma(y, self._last_pred, base_model_pred)  #finding optimal gamma\n",
    "            self.gammas.append(gamma)\n",
    "            self._last_pred += self.learning_rate * gamma * base_model_pred       #updating predictions\n",
    "            \n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"Make prediction of fitted boosting. \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "\n",
    "\n",
    "        Returns:\n",
    "          Prediction of fitted boosting.\n",
    "          \n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i in range(self.n_estimators):\n",
    "            y_pred += self.learning_rate * self.gammas[i] * self.models[i].predict(X)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Комментарии:*\n",
    "1. Добавил поле `_last_pred`, в котором записаны последние предсказания модели по всей выборке\n",
    "2. Обучаю базовые модели и считаю гамму на bootstrap-подвыборках\n",
    "3. Добавил параметр random_state в инициализаторе\n",
    "4. Добавил параметр show_progress, отвечающий за отображение шкалы прогресса в методе `fit`\n",
    "\n",
    "В остальном все стандартно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте вашу реализацию на бостонском датасете. Подберите оптимальные гиперпараметры, чтобы победить RandomForestRegressor (не меняйте параметры сида)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "192",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ibori\\Desktop\\Homeworks\\sem3\\ML_1\\homework_6.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m housing \u001b[39m=\u001b[39m fetch_california_housing()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m housing\u001b[39m.\u001b[39mdata[:\u001b[39m5000\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m housing\u001b[39m.\u001b[39mtarget[:\u001b[39m5000\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ibori\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_california_housing.py:150\u001b[0m, in \u001b[0;36mfetch_california_housing\u001b[1;34m(data_home, download_if_missing, return_X_y, as_frame)\u001b[0m\n\u001b[0;32m    147\u001b[0m     remove(archive_path)\n\u001b[0;32m    149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     cal_housing \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(filepath)\n\u001b[0;32m    152\u001b[0m feature_names \u001b[39m=\u001b[39m [\n\u001b[0;32m    153\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMedInc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHouseAge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    161\u001b[0m ]\n\u001b[0;32m    163\u001b[0m target, data \u001b[39m=\u001b[39m cal_housing[:, \u001b[39m0\u001b[39m], cal_housing[:, \u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\ibori\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 587\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\ibori\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    508\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    512\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ibori\\anaconda3\\lib\\pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1212\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39m)\n\u001b[0;32m   1213\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "\u001b[1;31mKeyError\u001b[0m: 192"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "X = housing.data[:5000]\n",
    "y = housing.target[:5000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ibori\\Desktop\\Homeworks\\sem3\\ML_1\\homework_6.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForestRegressor(max_features\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, n_estimators\u001b[39m=\u001b[39m\u001b[39m640\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m19052019\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rf_train_error \u001b[39m=\u001b[39m mean_squared_error(y_train, rf\u001b[39m.\u001b[39mpredict(X_train))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m rf_test_error \u001b[39m=\u001b[39m mean_squared_error(y_test, rf\u001b[39m.\u001b[39mpredict(X_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(max_features=4, n_estimators=640, random_state=19052019)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_error = mean_squared_error(y_train, rf.predict(X_train))\n",
    "rf_test_error = mean_squared_error(y_test, rf.predict(X_test))\n",
    "print(rf_train_error, rf_test_error, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в данном случае переобучена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncareful! runs for around 8 minutes!\\n\\nfor n_estimators in tqdm(range(5, 51, 5)):\\n    for max_depth in tqdm(range(1, 7)):\\n        for lr in range(1, 21):\\n            gb = GradientBoosting(n_estimators=n_estimators, base_model_params={'max_depth' : max_depth}, learning_rate=lr/100, random_state=19052019, show_progress=False)\\n            gb.fit(X_train, y_train)\\n\\n            err = mean_squared_error(y_test, gb.predict(X_test))\\n            if err < rf_error:\\n                print(f'error: {err}\\n n: {n_estimators}\\n max_depth: {max_depth}\\n learning_rate: {lr / 100}')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "careful! runs for around 8 minutes!\n",
    "\n",
    "for n_estimators in tqdm(range(5, 51, 5)):\n",
    "    for max_depth in tqdm(range(1, 7)):\n",
    "        for lr in range(1, 21):\n",
    "            gb = GradientBoosting(n_estimators=n_estimators, base_model_params={'max_depth' : max_depth}, learning_rate=lr/100, random_state=19052019, show_progress=False)\n",
    "            gb.fit(X_train, y_train)\n",
    "\n",
    "            err = mean_squared_error(y_test, gb.predict(X_test))\n",
    "            if err < rf_error:\n",
    "                print(f'error: {err}\\n n: {n_estimators}\\n max_depth: {max_depth}\\n learning_rate: {lr / 100}')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначально вручную удалось засечь, что начиная примерно с `max_depth = 5` и `learning_rate = 5 / n` модель начинает переобучаться, при этом изменения `n` особо не влияют (приходится понижать `learning rate` и получается то же самое, что логично). С помощью перебора выше удалось найти два набора параметров, при которых мы побеждаем случайный лес. При этом видно, что модель сильно переобучается. Мне кажется, что нам просто повезло, шум обучающей и тестовой выборки совпал и получилась относительно низкая ошибка. В реальности логично выбирать другие параметры, при которых на обучающей и тестовой выборке ошибка близка, но все равно какой-то степени переобучения избежать не удастся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 40.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049874058311388914\n",
      "0.16659537024916787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoosting(n_estimators=40, base_model_params={'max_depth' : 6}, learning_rate=0.17, random_state=19052019, show_progress=True)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "print(mean_squared_error(y_train, gb.predict(X_train)),\n",
    "      mean_squared_error(y_test, gb.predict(X_test)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Сравнение подходов (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте данные о выдаче кредитов. Это данные с kaggle, целевая переменная `y` показывает, вернуло ли кредит физическое лицо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>28</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.876</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>5008.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>38</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.742</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>32</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.965</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>40</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.334</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>57</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          job  marital          education default  housing     loan  \\\n",
       "6023   28      student   single  university.degree      no  unknown  unknown   \n",
       "3784   38   technician   single  university.degree      no      yes      yes   \n",
       "5658   32       admin.   single  university.degree      no       no       no   \n",
       "5941   40  blue-collar  married           basic.9y      no      yes       no   \n",
       "6309   57       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "       contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "6023  cellular   may         fri  ...         2    999         0  nonexistent   \n",
       "3784  cellular   jun         thu  ...         1    999         0  nonexistent   \n",
       "5658  cellular   aug         wed  ...         1    999         0  nonexistent   \n",
       "5941  cellular   may         wed  ...         1    999         0  nonexistent   \n",
       "6309  cellular   jul         mon  ...         2    999         0  nonexistent   \n",
       "\n",
       "     emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "6023         -1.8          93.876          -40.0      0.695       5008.7  1  \n",
       "3784         -1.7          94.055          -39.8      0.742       4991.6 -1  \n",
       "5658          1.4          93.444          -36.1      4.965       5228.1  1  \n",
       "5941         -1.8          92.893          -46.2      1.334       5099.1  1  \n",
       "6309          1.4          93.918          -42.7      4.960       5228.1 -1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://www.dropbox.com/s/uy27mctxo0gbuof/bank_data.csv?dl=1')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решите задачу предсказания возвращения кредита методами, перечисленными ниже:\n",
    "\n",
    "- Случайный лес\n",
    "- Бэггинг на деревьях (поставьте для базовых деревьев min_samples_leaf=1)\n",
    "- Бэггинг, у которого базовой моделью является бустинг с большим числом деревьев (> 100)\n",
    "- Бэггинг на логистических регрессиях\n",
    "\n",
    "Используйте логистическую регрессию, случайный лес, `GradientBoostingClassifier` и `BaggingClassifier` из `sklearn`.\n",
    "\n",
    "1) Какая из моделей имеет лучшее качество? С чем это связано?\n",
    "\n",
    "2) Какая из моделей сильнее всего переобучается?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала выделим категориальные признаки и применим one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.968</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.838</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0   39        67         3    999         0           1.4          93.918   \n",
       "1   31       522         1    999         0           1.4          93.918   \n",
       "2   34        84         1    999         0          -1.8          92.893   \n",
       "3   23       332         2    999         0           1.4          93.918   \n",
       "4   63       479         1    999         0          -2.9          92.201   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  ...  month_oct  month_sep  \\\n",
       "0          -42.7      4.968       5228.1  ...          0          0   \n",
       "1          -42.7      4.960       5228.1  ...          0          0   \n",
       "2          -46.2      1.250       5099.1  ...          0          0   \n",
       "3          -42.7      4.963       5228.1  ...          0          0   \n",
       "4          -31.4      0.838       5076.2  ...          0          0   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                0                0                1                0   \n",
       "1                0                1                0                0   \n",
       "2                1                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \n",
       "0                0                 0                     1                 0  \n",
       "1                0                 0                     1                 0  \n",
       "2                0                 0                     1                 0  \n",
       "3                1                 0                     1                 0  \n",
       "4                0                 0                     1                 0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'y']\n",
    "y = df.loc[:, \"y\"]\n",
    "numeric = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "for column in X.columns[~X.columns.isin(numeric)]:\n",
    "    one_hot = pd.get_dummies(X[column], prefix=column, dtype=int)\n",
    "    #print(one_hot)\n",
    "    X = X.drop(column, axis = 1)\n",
    "    X = X.join(one_hot)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ibori\\Desktop\\Homeworks\\sem3\\ML_1\\homework_6.ipynb Cell 21\u001b[0m line \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier(max_features\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, bootstrap\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dt \u001b[39m=\u001b[39m BaggingClassifier(estimator\u001b[39m=\u001b[39;49mDecisionTreeClassifier(min_samples_leaf\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), n_estimators\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, bootstrap\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m gb \u001b[39m=\u001b[39m BaggingClassifier(estimator\u001b[39m=\u001b[39mGradientBoostingClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m), n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, bootstrap\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/Homeworks/sem3/ML_1/homework_6.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m lr \u001b[39m=\u001b[39m BaggingClassifier(estimator\u001b[39m=\u001b[39mLogisticRegression(max_iter\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m), n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, bootstrap\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
    "\n",
    "rf = RandomForestClassifier(max_features=4, n_estimators=10, bootstrap=False)\n",
    "dt = BaggingClassifier(estimator=DecisionTreeClassifier(min_samples_leaf=1), n_estimators=10, bootstrap=False)\n",
    "gb = BaggingClassifier(estimator=GradientBoostingClassifier(n_estimators=200), n_estimators=10, bootstrap=False)\n",
    "lr = BaggingClassifier(estimator=LogisticRegression(max_iter=5000), n_estimators=10, bootstrap=False)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print('Random Forest trained')\n",
    "dt.fit(X_train, y_train)\n",
    "print('Bagging on Desicion Trees trained')\n",
    "gb.fit(X_train, y_train)\n",
    "print('Bagging on Gradient Boostings trained')\n",
    "lr.fit(X_train, y_train)\n",
    "print('Bagging on Logistic Regressions trained')\n",
    "\n",
    "rf_train_pred = rf.predict(X_train)\n",
    "dt_train_pred = dt.predict(X_train)\n",
    "gb_train_pred = gb.predict(X_train)\n",
    "lr_train_pred = lr.predict(X_train)\n",
    "\n",
    "rf_test_pred = rf.predict(X_test)\n",
    "dt_test_pred = dt.predict(X_test)\n",
    "gb_test_pred = gb.predict(X_test)\n",
    "lr_test_pred = lr.predict(X_test)\n",
    "\n",
    "data = [['Random Forest', \n",
    "            mean_squared_error(y_train, rf_train_pred), \n",
    "            mean_squared_error(y_test, rf_test_pred), \n",
    "            accuracy_score(y_test, rf_test_pred), \n",
    "            precision_score(y_test, rf_test_pred), \n",
    "            recall_score(y_test, rf_test_pred)],\n",
    "        ['Bagging on Desicion Trees', \n",
    "            mean_squared_error(y_train, dt_train_pred), \n",
    "            mean_squared_error(y_test, dt_test_pred), \n",
    "            accuracy_score(y_test, dt_test_pred), \n",
    "            precision_score(y_test, dt_test_pred), \n",
    "            recall_score(y_test, dt_test_pred)],\n",
    "        ['Bagging on Gradient Boostings', \n",
    "            mean_squared_error(y_train, gb_train_pred), \n",
    "            mean_squared_error(y_test, gb_test_pred), \n",
    "            accuracy_score(y_test, gb_test_pred), \n",
    "            precision_score(y_test, gb_test_pred), \n",
    "            recall_score(y_test, gb_test_pred)],\n",
    "        ['Bagging on Logistic Regressions', \n",
    "            mean_squared_error(y_train, lr_train_pred), \n",
    "            mean_squared_error(y_test, lr_test_pred), \n",
    "            accuracy_score(y_test, gb_test_pred), \n",
    "            precision_score(y_test, gb_test_pred), \n",
    "            recall_score(y_test, gb_test_pred)]]\n",
    "\n",
    "res = pd.DataFrame(data, columns=['model', 'train error', 'test error', 'accuracy', 'precision', 'recall'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Современные бустинги (3 балла)\n",
    "\n",
    "Сравните на этих данных любую из трёх популярных имплементаций градиентного бустинга (xgboost, lightgbm, catboost). Подберите основные гиперпараметры (число деревьев, длина шага, глубина дерева/число листьев). Получилось ли круче, чем с моделями выше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ibori\\Desktop\\ДЗ Совбак\\3 семестр\\Машинное обучение\\homework_6.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ibori/Desktop/%D0%94%D0%97%20%D0%A1%D0%BE%D0%B2%D0%B1%D0%B0%D0%BA/3%20%D1%81%D0%B5%D0%BC%D0%B5%D1%81%D1%82%D1%80/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5/homework_6.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcatboost\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw8-boosting-clustering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
